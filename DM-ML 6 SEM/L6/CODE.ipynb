{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["LOGISTIC REGRESSION"],"metadata":{"id":"XXufhXrgW9os"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewMJN75nRST4","outputId":"18b0bd76-402e-4aed-9d38-5b604b976835","executionInfo":{"status":"ok","timestamp":1679154352972,"user_tz":-330,"elapsed":6,"user":{"displayName":"160_Anushkka Dhamija","userId":"13118100216340839103"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["actual values= [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1]\n","predicted values= [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n","Accuracy calculated by acc_score=  0.85\n","Accuracy calculated by sklearn library function accuracy_scoree=  0.85\n"]}],"source":["actual=[1,0,0,1,0,0,1,0,0,1,1,0,0,0,0,1,0,1,0,1]\n","print(\"actual values=\", actual)\n","prediction_prob=[0.886,0.375,0.174,0.817,0.574,0.319,0.812,0.314,0.098,0.741,0.847,0.202,0.31,0.073,0.179,0.917,0.64,0.388,0.116,0.72]\n","\n","# (i) Write a function from scratch called predict() that computes the final predictions to be output by the model and returns them as a list\n","def predict(prediction_prob, threshold):\n","    predicted=list()\n","    for probability in prediction_prob:\n","        if probability<=threshold: predicted.append(0)\n","        else: predicted.append(1)\n","    print(\"predicted values=\",predicted)\n","    return predicted\n","\n","\n","# (ii) Write a function from scratch called acc_score() that calculates the model accuracy score using the true labels as compared to the predictions\n","def acc_score(actual, predicted):\n","    correct=0\n","    for i in range(len(actual)):\n","        if actual[i]==predicted[i]: correct+=1\n","    return correct/len(actual)\n","\n","\n","predicted=predict(prediction_prob, 0.5)\n","accuracy0=acc_score(actual, predicted)\n","\n","# (iii) Get the accuracy from sklearn then compare accuracy with output from the function acc_score()\n","from sklearn.metrics import accuracy_score\n","accuracy1=accuracy_score(actual, predicted)\n","\n","print('Accuracy calculated by acc_score= ', accuracy0)\n","print('Accuracy calculated by sklearn library function accuracy_scoree= ', accuracy1)"]}]}